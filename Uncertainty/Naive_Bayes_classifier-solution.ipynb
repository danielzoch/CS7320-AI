{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier for Spam Detection\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: 10\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with \n",
    "\n",
    "* your implementation,\n",
    "* documentation including a short discussion of how your implementation works and your design choices, and\n",
    "* experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. \n",
    "\n",
    "Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "A spam detection agent gets as its percepts text messages and needs to decide if they are spam or not.\n",
    "Create a [naive Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) for the \n",
    "[UCI SMS Spam Collection Data Set](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) to perform this task.\n",
    "\n",
    "__About the use of libraries:__ The point of this exercise is to learn how a Bayes classifier is built. You may use libraries for tokenizing, stop words and to create a document-term matrix, but you need to implement parameter estimation and prediction yourself.\n",
    "\n",
    "## Create a bag-of-words representation of the text messages [3 Points]\n",
    "\n",
    "The first step is to tokenize the text. Here is an example of how to load the data as a Pandas dataframe and then hoe to use the [natural language tool kit (nltk)](https://www.nltk.org/) to create tokens (separate terms) for the first message in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"smsspamcollection/SMSSpamCollection\", sep='\\t',header = None,names = [\"label\",\"sms\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message: Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat... (label: ham)\n",
      "tokens: ['Go', 'until', 'jurong', 'point', ',', 'crazy', '..', 'Available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', '...', 'Cine', 'there', 'got', 'amore', 'wat', '...']\n"
     ]
    }
   ],
   "source": [
    "# ! pip install nltk\n",
    "import nltk\n",
    "# You need to install nltk and then download the punctuation database for the tokenizer.\n",
    "# nltk.download('punkt')\n",
    "\n",
    "message = data.at[0,'sms']\n",
    "label = data.at[0,'label']\n",
    "print(f\"message: {message} (label: {label})\")\n",
    "\n",
    "tokens = nltk.word_tokenize(message)\n",
    "print(f\"tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with removing frequent words (called [stopwords](https://en.wikipedia.org/wiki/Stop_word)) and very infrequent words so you end up with a reasonable number of words used in the classifier. Maybe you need to remove digits or all non-letter characters. You may also use a stemming algorithm. \n",
    "\n",
    "Convert the tokenized data into a data structure that indicates for each for document what words it contains. The data structure can be a [document-term matrix](https://en.wikipedia.org/wiki/Document-term_matrix) with 0s and 1s, a pandas dataframe or some sparse matrix structure. Note: words, tokens and terms are often used interchangably. Make sure the data structure can be used to split the data into training and test documents (see below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x8713 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 74169 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "#vectorizer = CountVectorizer(binary = True, stop_words='english')\n",
    "vectorizer = CountVectorizer(binary = True)\n",
    "X = vectorizer.fit_transform(data['sms'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spam = X[data['label'] == \"spam\"]\n",
    "X_ham = X[data['label'] == \"ham\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8713"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = pd.DataFrame({\n",
    "    'term' : vectorizer.get_feature_names(), \n",
    "    'doc_freq' : np.squeeze(np.asarray(X.sum(axis = 0))),\n",
    "    'spam_freq' : np.squeeze(np.asarray(X_spam.sum(axis = 0))),\n",
    "    'ham_freq' : np.squeeze(np.asarray(X_ham.sum(axis = 0)))\n",
    "})\n",
    "\n",
    "terms = terms.sort_values('doc_freq', ascending=False)\n",
    "\n",
    "len(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>doc_freq</th>\n",
       "      <th>spam_freq</th>\n",
       "      <th>ham_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7806</th>\n",
       "      <td>to</td>\n",
       "      <td>1687</td>\n",
       "      <td>468</td>\n",
       "      <td>1219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8668</th>\n",
       "      <td>you</td>\n",
       "      <td>1591</td>\n",
       "      <td>242</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7674</th>\n",
       "      <td>the</td>\n",
       "      <td>1035</td>\n",
       "      <td>167</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>in</td>\n",
       "      <td>810</td>\n",
       "      <td>70</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>and</td>\n",
       "      <td>795</td>\n",
       "      <td>108</td>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>is</td>\n",
       "      <td>752</td>\n",
       "      <td>142</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4968</th>\n",
       "      <td>me</td>\n",
       "      <td>690</td>\n",
       "      <td>27</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3323</th>\n",
       "      <td>for</td>\n",
       "      <td>624</td>\n",
       "      <td>179</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4245</th>\n",
       "      <td>it</td>\n",
       "      <td>614</td>\n",
       "      <td>29</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5254</th>\n",
       "      <td>my</td>\n",
       "      <td>613</td>\n",
       "      <td>12</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>your</td>\n",
       "      <td>587</td>\n",
       "      <td>227</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1828</th>\n",
       "      <td>call</td>\n",
       "      <td>550</td>\n",
       "      <td>328</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5511</th>\n",
       "      <td>of</td>\n",
       "      <td>550</td>\n",
       "      <td>94</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>have</td>\n",
       "      <td>531</td>\n",
       "      <td>127</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7670</th>\n",
       "      <td>that</td>\n",
       "      <td>512</td>\n",
       "      <td>26</td>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>on</td>\n",
       "      <td>488</td>\n",
       "      <td>121</td>\n",
       "      <td>367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5453</th>\n",
       "      <td>now</td>\n",
       "      <td>481</td>\n",
       "      <td>190</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>are</td>\n",
       "      <td>445</td>\n",
       "      <td>76</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7074</th>\n",
       "      <td>so</td>\n",
       "      <td>433</td>\n",
       "      <td>26</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>can</td>\n",
       "      <td>425</td>\n",
       "      <td>29</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      term  doc_freq  spam_freq  ham_freq\n",
       "7806    to      1687        468      1219\n",
       "8668   you      1591        242      1349\n",
       "7674   the      1035        167       868\n",
       "4114    in       810         70       740\n",
       "1097   and       795        108       687\n",
       "4233    is       752        142       610\n",
       "4968    me       690         27       663\n",
       "3323   for       624        179       445\n",
       "4245    it       614         29       585\n",
       "5254    my       613         12       601\n",
       "8674  your       587        227       360\n",
       "1828  call       550        328       222\n",
       "5511    of       550         94       456\n",
       "3794  have       531        127       404\n",
       "7670  that       512         26       486\n",
       "5559    on       488        121       367\n",
       "5453   now       481        190       291\n",
       "1196   are       445         76       369\n",
       "7074    so       433         26       407\n",
       "1853   can       425         29       396"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms.head(n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>doc_freq</th>\n",
       "      <th>spam_freq</th>\n",
       "      <th>ham_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>healer</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>heal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3812</th>\n",
       "      <td>headstart</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3811</th>\n",
       "      <td>headset</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>hdd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>hcl</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3801</th>\n",
       "      <td>havn</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>haventcn</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>havebeen</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>havbeen</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3792</th>\n",
       "      <td>hava</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>hav2hear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3789</th>\n",
       "      <td>haunt</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>haul</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>haughaighgtujhyguj</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>hates</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>hat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>hassling</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3782</th>\n",
       "      <td>hasnt</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8712</th>\n",
       "      <td>〨ud</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    term  doc_freq  spam_freq  ham_freq\n",
       "3814              healer         1          0         1\n",
       "3813                heal         1          0         1\n",
       "3812           headstart         1          0         1\n",
       "3811             headset         1          1         0\n",
       "3804                 hdd         1          0         1\n",
       "3803                 hcl         1          0         1\n",
       "3801                havn         1          0         1\n",
       "3798            haventcn         1          0         1\n",
       "3795            havebeen         1          0         1\n",
       "3793             havbeen         1          0         1\n",
       "3792                hava         1          1         0\n",
       "3791            hav2hear         1          0         1\n",
       "3789               haunt         1          0         1\n",
       "3788                haul         1          0         1\n",
       "3787  haughaighgtujhyguj         1          0         1\n",
       "3786               hates         1          0         1\n",
       "3784                 hat         1          0         1\n",
       "3783            hassling         1          0         1\n",
       "3782               hasnt         1          0         1\n",
       "8712                 〨ud         1          0         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms.tail(n = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the 20 most frequent and the 20 least frequent words and there frequency in your data set. Remember: words are only counted once per document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that prints the tables with the words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn parameters [3 Points]\n",
    "\n",
    "Use 80% of the data (called training set; randomly chosen) to learn the parameters of the naive Bayes classifier (prior probabilities and likelihoods). \n",
    "Remember, the naive Bayes classifier assumes conditional independence between words and estimates porteriori probabilities as:\n",
    "\n",
    "$$\\hat{P}(spam|message) \\propto score_{spam}(message) = P(spam) \\prod_{i=1}^n P(w_i | spam)$$\n",
    "$$\\hat{P}(ham|message) \\propto score_{ham}(message) = P(ham) \\prod_{i=1}^n P(w_i | ham)$$\n",
    "\n",
    "Messages are classified as spam if the posteriori probability for spam is larger than for ham which is\n",
    "equivalent to \n",
    "$$score_{spam}(message) > score_{ham}(message)$$ \n",
    "\n",
    "You therefore need to\n",
    "estimate \n",
    "\n",
    "* the priors $P(spam)$ and $P(ham)$ for messages, and \n",
    "* the likelihoods $P(w_i | spam)$ and $P(w_i | ham)$ for all the words/tokens you chose to use\n",
    "\n",
    "from counts obtained from the training data. Use [Laplacian smoothing](https://en.wikipedia.org/wiki/Additive_smoothing) for the estimation of\n",
    "likelihoods to avoid likelihoods of zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "y = data[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the prior probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8658290329818263"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_ham = sum(y_train == 'ham')\n",
    "P_ham = n_ham / len(y_train)\n",
    "P_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13417096701817366"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_spam = sum(y_train == 'spam')\n",
    "P_spam = n_spam / len(y_train)\n",
    "P_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate log of priors for later\n",
    "log_P_ham = np.log(P_ham)\n",
    "log_P_spam = np.log(P_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>doc_freq</th>\n",
       "      <th>spam_freq</th>\n",
       "      <th>ham_freq</th>\n",
       "      <th>likelihood_spam</th>\n",
       "      <th>likelihood_ham</th>\n",
       "      <th>likelihood_ratio</th>\n",
       "      <th>log_likelihood_spam</th>\n",
       "      <th>log_likelihood_ham</th>\n",
       "      <th>log_likelihood_not_spam</th>\n",
       "      <th>log_likelihood_not_ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>57.9150</td>\n",
       "      <td>-4.199705</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.015114</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038333</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>148.0050</td>\n",
       "      <td>-3.261435</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.039087</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000pes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>3.2175</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-7.565534</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>008704050406</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>19.3050</td>\n",
       "      <td>-5.298317</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.005013</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0089</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>12.8700</td>\n",
       "      <td>-5.703782</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.003339</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           term  doc_freq  spam_freq  ham_freq  likelihood_spam  \\\n",
       "0            00         8          8         0         0.015000   \n",
       "1           000        22         22         0         0.038333   \n",
       "2        000pes         1          0         1         0.001667   \n",
       "3  008704050406         2          2         0         0.005000   \n",
       "4          0089         1          1         0         0.003333   \n",
       "\n",
       "   likelihood_ham  likelihood_ratio  log_likelihood_spam  log_likelihood_ham  \\\n",
       "0        0.000259           57.9150            -4.199705           -8.258681   \n",
       "1        0.000259          148.0050            -3.261435           -8.258681   \n",
       "2        0.000518            3.2175            -6.396930           -7.565534   \n",
       "3        0.000259           19.3050            -5.298317           -8.258681   \n",
       "4        0.000259           12.8700            -5.703782           -8.258681   \n",
       "\n",
       "   log_likelihood_not_spam  log_likelihood_not_ham  \n",
       "0                -0.015114               -0.000259  \n",
       "1                -0.039087               -0.000259  \n",
       "2                -0.001668               -0.000518  \n",
       "3                -0.005013               -0.000259  \n",
       "4                -0.003339               -0.000259  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate term frequencies (column sums)\n",
    "terms = pd.DataFrame({\n",
    "    'term' : vectorizer.get_feature_names(), \n",
    "    'doc_freq' : np.squeeze(np.asarray(X_train.sum(axis = 0))),\n",
    "    'spam_freq' : np.squeeze(np.asarray(X_train[y_train == \"spam\"].sum(axis = 0))),\n",
    "    'ham_freq' : np.squeeze(np.asarray(X_train[y_train == \"ham\"].sum(axis = 0)))\n",
    "})\n",
    "\n",
    "# for Laplace smoothing\n",
    "alpha = 1\n",
    "n_classes = 2\n",
    "\n",
    "# calculate likelihoods and log likelihoods\n",
    "terms['likelihood_spam'] = (terms['spam_freq'] + alpha) / (n_spam + n_classes) \n",
    "terms['likelihood_ham'] = (terms['ham_freq'] + alpha) / (n_ham + n_classes) \n",
    "\n",
    "terms['likelihood_ratio'] = terms['likelihood_spam'] / terms['likelihood_ham']\n",
    "\n",
    "terms['log_likelihood_spam'] = np.log(terms['likelihood_spam']) \n",
    "terms['log_likelihood_ham'] = np.log(terms['likelihood_ham']) \n",
    "\n",
    "# we also need the log likelihood of a term not being in spam/ham\n",
    "terms['log_likelihood_not_spam'] = np.log(1-terms['likelihood_spam']) \n",
    "terms['log_likelihood_not_ham'] = np.log(1-terms['likelihood_ham']) \n",
    "\n",
    "terms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the top 20 words (highest conditional probability) for ham and for spam. These words represent the biggest clues that a message is ham or spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>doc_freq</th>\n",
       "      <th>spam_freq</th>\n",
       "      <th>ham_freq</th>\n",
       "      <th>likelihood_spam</th>\n",
       "      <th>likelihood_ham</th>\n",
       "      <th>likelihood_ratio</th>\n",
       "      <th>log_likelihood_spam</th>\n",
       "      <th>log_likelihood_ham</th>\n",
       "      <th>log_likelihood_not_spam</th>\n",
       "      <th>log_likelihood_not_ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4793</th>\n",
       "      <td>lt</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.050764</td>\n",
       "      <td>0.032832</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-2.980567</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.052098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>gt</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>194</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-2.985682</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.051825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3805</th>\n",
       "      <td>he</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>0.048750</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-3.375880</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.034786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>lor</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>0.055957</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-3.513749</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.030238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4550</th>\n",
       "      <td>later</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.029008</td>\n",
       "      <td>0.057455</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-3.540183</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.029437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2428</th>\n",
       "      <td>da</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.027713</td>\n",
       "      <td>0.060140</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-3.585853</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.028104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6843</th>\n",
       "      <td>she</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.024605</td>\n",
       "      <td>0.067737</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-3.704805</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.024913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5533</th>\n",
       "      <td>oh</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.022533</td>\n",
       "      <td>0.073966</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-3.792773</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.022791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>doing</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.019425</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-3.941193</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.019616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>already</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.017612</td>\n",
       "      <td>0.094632</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-4.039174</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.017769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>ask</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.016058</td>\n",
       "      <td>0.103790</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-4.131547</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.016188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6626</th>\n",
       "      <td>said</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.015799</td>\n",
       "      <td>0.105492</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-4.147808</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.015925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>morning</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.015540</td>\n",
       "      <td>0.107250</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-4.164337</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.015662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7126</th>\n",
       "      <td>sorry</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.030821</td>\n",
       "      <td>0.108151</td>\n",
       "      <td>-5.703782</td>\n",
       "      <td>-3.479558</td>\n",
       "      <td>-0.003339</td>\n",
       "      <td>-0.031306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>come</td>\n",
       "      <td>174</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.044807</td>\n",
       "      <td>0.111590</td>\n",
       "      <td>-5.298317</td>\n",
       "      <td>-3.105390</td>\n",
       "      <td>-0.005013</td>\n",
       "      <td>-0.045842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>amp</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.014504</td>\n",
       "      <td>0.114911</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-4.233330</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.014610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2289</th>\n",
       "      <td>cos</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.014504</td>\n",
       "      <td>0.114911</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-4.233330</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.014610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>something</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.014245</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-4.251348</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.014347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>anything</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.119167</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-4.269697</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.014085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4724</th>\n",
       "      <td>lol</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>0.119167</td>\n",
       "      <td>-6.396930</td>\n",
       "      <td>-4.269697</td>\n",
       "      <td>-0.001668</td>\n",
       "      <td>-0.014085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           term  doc_freq  spam_freq  ham_freq  likelihood_spam  \\\n",
       "4793         lt       195          0       195         0.001667   \n",
       "3684         gt       194          0       194         0.001667   \n",
       "3805         he       131          0       131         0.001667   \n",
       "4747        lor       114          0       114         0.001667   \n",
       "4550      later       111          0       111         0.001667   \n",
       "2428         da       106          0       106         0.001667   \n",
       "6843        she        94          0        94         0.001667   \n",
       "5533         oh        86          0        86         0.001667   \n",
       "2714      doing        74          0        74         0.001667   \n",
       "1054    already        67          0        67         0.001667   \n",
       "1247        ask        61          0        61         0.001667   \n",
       "6626       said        60          0        60         0.001667   \n",
       "5167    morning        59          0        59         0.001667   \n",
       "7126      sorry       119          1       118         0.003333   \n",
       "2163       come       174          2       172         0.005000   \n",
       "1084        amp        55          0        55         0.001667   \n",
       "2289        cos        55          0        55         0.001667   \n",
       "7099  something        54          0        54         0.001667   \n",
       "1142   anything        53          0        53         0.001667   \n",
       "4724        lol        53          0        53         0.001667   \n",
       "\n",
       "      likelihood_ham  likelihood_ratio  log_likelihood_spam  \\\n",
       "4793        0.050764          0.032832            -6.396930   \n",
       "3684        0.050505          0.033000            -6.396930   \n",
       "3805        0.034188          0.048750            -6.396930   \n",
       "4747        0.029785          0.055957            -6.396930   \n",
       "4550        0.029008          0.057455            -6.396930   \n",
       "2428        0.027713          0.060140            -6.396930   \n",
       "6843        0.024605          0.067737            -6.396930   \n",
       "5533        0.022533          0.073966            -6.396930   \n",
       "2714        0.019425          0.085800            -6.396930   \n",
       "1054        0.017612          0.094632            -6.396930   \n",
       "1247        0.016058          0.103790            -6.396930   \n",
       "6626        0.015799          0.105492            -6.396930   \n",
       "5167        0.015540          0.107250            -6.396930   \n",
       "7126        0.030821          0.108151            -5.703782   \n",
       "2163        0.044807          0.111590            -5.298317   \n",
       "1084        0.014504          0.114911            -6.396930   \n",
       "2289        0.014504          0.114911            -6.396930   \n",
       "7099        0.014245          0.117000            -6.396930   \n",
       "1142        0.013986          0.119167            -6.396930   \n",
       "4724        0.013986          0.119167            -6.396930   \n",
       "\n",
       "      log_likelihood_ham  log_likelihood_not_spam  log_likelihood_not_ham  \n",
       "4793           -2.980567                -0.001668               -0.052098  \n",
       "3684           -2.985682                -0.001668               -0.051825  \n",
       "3805           -3.375880                -0.001668               -0.034786  \n",
       "4747           -3.513749                -0.001668               -0.030238  \n",
       "4550           -3.540183                -0.001668               -0.029437  \n",
       "2428           -3.585853                -0.001668               -0.028104  \n",
       "6843           -3.704805                -0.001668               -0.024913  \n",
       "5533           -3.792773                -0.001668               -0.022791  \n",
       "2714           -3.941193                -0.001668               -0.019616  \n",
       "1054           -4.039174                -0.001668               -0.017769  \n",
       "1247           -4.131547                -0.001668               -0.016188  \n",
       "6626           -4.147808                -0.001668               -0.015925  \n",
       "5167           -4.164337                -0.001668               -0.015662  \n",
       "7126           -3.479558                -0.003339               -0.031306  \n",
       "2163           -3.105390                -0.005013               -0.045842  \n",
       "1084           -4.233330                -0.001668               -0.014610  \n",
       "2289           -4.233330                -0.001668               -0.014610  \n",
       "7099           -4.251348                -0.001668               -0.014347  \n",
       "1142           -4.269697                -0.001668               -0.014085  \n",
       "4724           -4.269697                -0.001668               -0.014085  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ham\n",
    "terms.sort_values('likelihood_ratio', ascending=True).head(n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>doc_freq</th>\n",
       "      <th>spam_freq</th>\n",
       "      <th>ham_freq</th>\n",
       "      <th>likelihood_spam</th>\n",
       "      <th>likelihood_ham</th>\n",
       "      <th>likelihood_ratio</th>\n",
       "      <th>log_likelihood_spam</th>\n",
       "      <th>log_likelihood_ham</th>\n",
       "      <th>log_likelihood_not_spam</th>\n",
       "      <th>log_likelihood_not_ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>16</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>135.135</td>\n",
       "      <td>-2.659260</td>\n",
       "      <td>-7.565534</td>\n",
       "      <td>-0.072571</td>\n",
       "      <td>-0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>collection</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>141.570</td>\n",
       "      <td>-3.305887</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.037356</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038333</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>148.005</td>\n",
       "      <td>-3.261435</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.039087</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8375</th>\n",
       "      <td>weekly</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038333</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>148.005</td>\n",
       "      <td>-3.261435</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.039087</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6284</th>\n",
       "      <td>rate</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043333</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>167.310</td>\n",
       "      <td>-3.138833</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.044300</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6525</th>\n",
       "      <td>ringtone</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043333</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>167.310</td>\n",
       "      <td>-3.138833</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.044300</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>150ppm</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>173.745</td>\n",
       "      <td>-3.101093</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.046044</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8016</th>\n",
       "      <td>uk</td>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>173.745</td>\n",
       "      <td>-2.407946</td>\n",
       "      <td>-7.565534</td>\n",
       "      <td>-0.094311</td>\n",
       "      <td>-0.000518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8596</th>\n",
       "      <td>www</td>\n",
       "      <td>82</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>0.135000</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>173.745</td>\n",
       "      <td>-2.002481</td>\n",
       "      <td>-7.160069</td>\n",
       "      <td>-0.145026</td>\n",
       "      <td>-0.000777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>awarded</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>212.355</td>\n",
       "      <td>-2.900422</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.056570</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1000</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>218.790</td>\n",
       "      <td>-2.870569</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.058336</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7837</th>\n",
       "      <td>tone</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>225.225</td>\n",
       "      <td>-2.841582</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.060104</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>100</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>225.225</td>\n",
       "      <td>-2.841582</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.060104</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>cs</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>231.660</td>\n",
       "      <td>-2.813411</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.061875</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>500</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0.061667</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>238.095</td>\n",
       "      <td>-2.786012</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.063650</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>guaranteed</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068333</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>263.835</td>\n",
       "      <td>-2.683358</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.070780</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068333</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>263.835</td>\n",
       "      <td>-2.683358</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.070780</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>150p</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>353.925</td>\n",
       "      <td>-2.389596</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.096144</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6113</th>\n",
       "      <td>prize</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.098333</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>379.665</td>\n",
       "      <td>-2.319392</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.103510</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>claim</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>540.540</td>\n",
       "      <td>-1.966113</td>\n",
       "      <td>-8.258681</td>\n",
       "      <td>-0.150823</td>\n",
       "      <td>-0.000259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            term  doc_freq  spam_freq  ham_freq  likelihood_spam  \\\n",
       "364           16        42         41         1         0.070000   \n",
       "2150  collection        21         21         0         0.036667   \n",
       "1            000        22         22         0         0.038333   \n",
       "8375      weekly        22         22         0         0.038333   \n",
       "6284        rate        25         25         0         0.043333   \n",
       "6525    ringtone        25         25         0         0.043333   \n",
       "356       150ppm        26         26         0         0.045000   \n",
       "8016          uk        54         53         1         0.090000   \n",
       "8596         www        82         80         2         0.135000   \n",
       "1333     awarded        32         32         0         0.055000   \n",
       "299         1000        33         33         0         0.056667   \n",
       "7837        tone        34         34         0         0.058333   \n",
       "298          100        34         34         0         0.058333   \n",
       "2371          cs        35         35         0         0.060000   \n",
       "617          500        36         36         0         0.061667   \n",
       "3688  guaranteed        40         40         0         0.068333   \n",
       "369           18        40         40         0         0.068333   \n",
       "352         150p        54         54         0         0.091667   \n",
       "6113       prize        58         58         0         0.098333   \n",
       "2067       claim        83         83         0         0.140000   \n",
       "\n",
       "      likelihood_ham  likelihood_ratio  log_likelihood_spam  \\\n",
       "364         0.000518           135.135            -2.659260   \n",
       "2150        0.000259           141.570            -3.305887   \n",
       "1           0.000259           148.005            -3.261435   \n",
       "8375        0.000259           148.005            -3.261435   \n",
       "6284        0.000259           167.310            -3.138833   \n",
       "6525        0.000259           167.310            -3.138833   \n",
       "356         0.000259           173.745            -3.101093   \n",
       "8016        0.000518           173.745            -2.407946   \n",
       "8596        0.000777           173.745            -2.002481   \n",
       "1333        0.000259           212.355            -2.900422   \n",
       "299         0.000259           218.790            -2.870569   \n",
       "7837        0.000259           225.225            -2.841582   \n",
       "298         0.000259           225.225            -2.841582   \n",
       "2371        0.000259           231.660            -2.813411   \n",
       "617         0.000259           238.095            -2.786012   \n",
       "3688        0.000259           263.835            -2.683358   \n",
       "369         0.000259           263.835            -2.683358   \n",
       "352         0.000259           353.925            -2.389596   \n",
       "6113        0.000259           379.665            -2.319392   \n",
       "2067        0.000259           540.540            -1.966113   \n",
       "\n",
       "      log_likelihood_ham  log_likelihood_not_spam  log_likelihood_not_ham  \n",
       "364            -7.565534                -0.072571               -0.000518  \n",
       "2150           -8.258681                -0.037356               -0.000259  \n",
       "1              -8.258681                -0.039087               -0.000259  \n",
       "8375           -8.258681                -0.039087               -0.000259  \n",
       "6284           -8.258681                -0.044300               -0.000259  \n",
       "6525           -8.258681                -0.044300               -0.000259  \n",
       "356            -8.258681                -0.046044               -0.000259  \n",
       "8016           -7.565534                -0.094311               -0.000518  \n",
       "8596           -7.160069                -0.145026               -0.000777  \n",
       "1333           -8.258681                -0.056570               -0.000259  \n",
       "299            -8.258681                -0.058336               -0.000259  \n",
       "7837           -8.258681                -0.060104               -0.000259  \n",
       "298            -8.258681                -0.060104               -0.000259  \n",
       "2371           -8.258681                -0.061875               -0.000259  \n",
       "617            -8.258681                -0.063650               -0.000259  \n",
       "3688           -8.258681                -0.070780               -0.000259  \n",
       "369            -8.258681                -0.070780               -0.000259  \n",
       "352            -8.258681                -0.096144               -0.000259  \n",
       "6113           -8.258681                -0.103510               -0.000259  \n",
       "2067           -8.258681                -0.150823               -0.000259  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spam\n",
    "terms.sort_values('likelihood_ratio', ascending=True).tail(n = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the classification performance [4 Points] \n",
    "\n",
    "Classify the remaining 20% of the data (test set) and calculate classification accuracy. Accuracy is defined as the proportion of correctly classified test documents (see https://github.com/mhahsler/CS7320-AI/blob/master/ML/ML_example.ipynb).\n",
    "\n",
    "1. How good is your classifier's accuracy compared to the baseline classifier that always predicts the majority class. You can also compare your classifier with the [Naive Bayes classifier implemented in sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB). \n",
    "\n",
    "2. Inspect a few misclassified text messages and discuss why the classification failed.\n",
    "\n",
    "3. Discuss how you deal with words in the test data that you have not seen in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak baseline test accuracy (always predict ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8663677130044843"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(['ham'] * len(y_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong baseline test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847533632286996"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "clf = BernoulliNB(alpha = 1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priors (log): [-0.14406781 -2.00864042]\n",
      "Loglikelihoods: [[-8.2586815  -8.2586815  -7.56553432 ... -7.56553432 -8.2586815\n",
      "  -8.2586815 ]\n",
      " [-4.19970508 -3.26143544 -6.39692966 ... -6.39692966 -5.70378247\n",
      "  -6.39692966]]\n"
     ]
    }
   ],
   "source": [
    "# look at model parameters\n",
    "print(f\"Priors (log): {clf.class_log_prior_}\")\n",
    "print(f\"Loglikelihoods: {clf.feature_log_prob_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99999991e-01, 9.16080713e-09],\n",
       "       [9.99999970e-01, 3.02570471e-08],\n",
       "       [1.00000000e+00, 3.26475627e-13],\n",
       "       [1.00000000e+00, 1.29121253e-13],\n",
       "       [9.99999853e-01, 1.47208670e-07]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log probability score for first five test example\n",
    "clf.predict_proba(X_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "Calculate scores by summing the log likelihoods for words in the message and words not in the message. \n",
    "Since the messages are short, it is more efficient to start with the score for no words in the message and subtract the score of the words that are in it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_ham</th>\n",
       "      <th>score_spam</th>\n",
       "      <th>P_ham</th>\n",
       "      <th>P_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.798820e-51</td>\n",
       "      <td>3.480026e-59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.160807e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.083092e-52</td>\n",
       "      <td>1.840564e-59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.025705e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.659536e-35</td>\n",
       "      <td>2.174176e-47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.264756e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.583173e-25</td>\n",
       "      <td>2.044212e-38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.291213e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.814751e-42</td>\n",
       "      <td>4.143558e-49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.472087e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score_ham    score_spam  P_ham        P_spam\n",
       "0  3.798820e-51  3.480026e-59    1.0  9.160807e-09\n",
       "1  6.083092e-52  1.840564e-59    1.0  3.025705e-08\n",
       "2  6.659536e-35  2.174176e-47    1.0  3.264756e-13\n",
       "3  1.583173e-25  2.044212e-38    1.0  1.291213e-13\n",
       "4  2.814751e-42  4.143558e-49    1.0  1.472087e-07"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " sum_score_not_ham = sum(terms['log_likelihood_not_ham'])\n",
    "sum_score_not_spam = sum(terms['log_likelihood_not_spam'])\n",
    "\n",
    "# @ is the dot product\n",
    "pred = pd.DataFrame({\n",
    "    'score_ham' : np.exp(X_test @ terms['log_likelihood_ham'] + \n",
    "                         (sum_score_not_ham - X_test @ terms['log_likelihood_not_ham']) + \n",
    "                         log_P_ham),\n",
    "    'score_spam': np.exp(X_test @ terms['log_likelihood_spam'] + \n",
    "                         (sum_score_not_spam - X_test @ terms['log_likelihood_not_spam']) + \n",
    "                         log_P_spam)\n",
    "})\n",
    "\n",
    "# normalize to probabilities\n",
    "pred['P_ham'] = pred['score_ham'] / (pred['score_ham'] + pred['score_spam'])\n",
    "pred['P_spam'] = pred['score_spam'] / (pred['score_ham'] + pred['score_spam'])\n",
    "\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_ham</th>\n",
       "      <th>score_spam</th>\n",
       "      <th>P_ham</th>\n",
       "      <th>P_spam</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.798820e-51</td>\n",
       "      <td>3.480026e-59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.160807e-09</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.083092e-52</td>\n",
       "      <td>1.840564e-59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.025705e-08</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.659536e-35</td>\n",
       "      <td>2.174176e-47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.264756e-13</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.583173e-25</td>\n",
       "      <td>2.044212e-38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.291213e-13</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.814751e-42</td>\n",
       "      <td>4.143558e-49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.472087e-07</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score_ham    score_spam  P_ham        P_spam class\n",
       "0  3.798820e-51  3.480026e-59    1.0  9.160807e-09   ham\n",
       "1  6.083092e-52  1.840564e-59    1.0  3.025705e-08   ham\n",
       "2  6.659536e-35  2.174176e-47    1.0  3.264756e-13   ham\n",
       "3  1.583173e-25  2.044212e-38    1.0  1.291213e-13   ham\n",
       "4  2.814751e-42  4.143558e-49    1.0  1.472087e-07   ham"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred['class'] = (pred['P_spam'] > pred['P_ham']).map({True : 'spam', False : 'ham'})\n",
    "pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847533632286996"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred['class'], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[963,  14],\n",
       "       [  3, 135]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(pred['class'], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to find the misclassified message, I resplit the original data\n",
    "message_train, message_test, y_train, y_test = train_test_split(data['sms'], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>y</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>Keep ur problems in ur heart, b'coz nobody wil...</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>Nowadays people are notixiquating the laxinorf...</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>Si.como no?!listened2the plaid album-quite gd&amp;...</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Reminder: You have not downloaded the content ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>PRIVATE! Your 2003 Account Statement for 078</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>Mobile Club: Choose any of the top quality ite...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>Sorry I missed your call let's talk when you h...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>Talk sexy!! Make new friends or fall in love i...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>Bloomberg -Message center +447797706009 Why wa...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Bloomberg -Message center +447797706009 Why wa...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Do you realize that in about 40 years, we'll h...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Hello darling how are you today? I would love ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Babe: U want me dont u baby! Im nasty and have...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Your next amazing xxx PICSFREE1 video will be ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>Email AlertFrom: Jeri StewartSize: 2KBSubject:...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>You have 1 new message. Please call 08712400200.</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                message     y  pred\n",
       "707   Keep ur problems in ur heart, b'coz nobody wil...   ham  spam\n",
       "562   Nowadays people are notixiquating the laxinorf...   ham  spam\n",
       "360   Si.como no?!listened2the plaid album-quite gd&...   ham  spam\n",
       "40    Reminder: You have not downloaded the content ...  spam   ham\n",
       "927        PRIVATE! Your 2003 Account Statement for 078  spam   ham\n",
       "678   Mobile Club: Choose any of the top quality ite...  spam   ham\n",
       "635   Sorry I missed your call let's talk when you h...  spam   ham\n",
       "561   Talk sexy!! Make new friends or fall in love i...  spam   ham\n",
       "550   Bloomberg -Message center +447797706009 Why wa...  spam   ham\n",
       "324   Bloomberg -Message center +447797706009 Why wa...  spam   ham\n",
       "272   Do you realize that in about 40 years, we'll h...  spam   ham\n",
       "234   Hello darling how are you today? I would love ...  spam   ham\n",
       "160   Babe: U want me dont u baby! Im nasty and have...  spam   ham\n",
       "84    Your next amazing xxx PICSFREE1 video will be ...  spam   ham\n",
       "74    Oh my god! I've found your number again! I'm s...  spam   ham\n",
       "1081  Email AlertFrom: Jeri StewartSize: 2KBSubject:...  spam   ham\n",
       "1107   You have 1 new message. Please call 08712400200.  spam   ham"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame({'message' : message_test.reset_index(drop = True), \n",
    "              'y' : y_test.reset_index(drop = True), \n",
    "              'pred' : pred['class'].reset_index(drop = True)\n",
    "                   })\n",
    "             \n",
    "res[ res.y != res.pred ].sort_values(by = 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus task [+1 Point]\n",
    "\n",
    "Describe how you could improve the classifier. Implement and test one of the improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code goes here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
